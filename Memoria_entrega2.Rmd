---
title: "Memoria_Practica2"
author: "Lara"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
    toc: yes
    toc_float:
      collapsed: true
---

```{r echo=FALSE}
library(readr)
library(ggplot2)
library(dplyr)
library(HDclassif)
library(MASS)
library(gt)
library(knitr)
library(cluster)
library (tidyverse)
library (factoextra)
library (NbClust)
library (parameters)
library (stats)
library(summarytools)
library(corrplot)
```

```{r echo = FALSE}
obesidad <- read.csv("C:/Users/laram/Downloads/archive (3)/ObesityDataSet.csv")
data <- dim(obesidad)
```

```{r echo = FALSE}
set.seed(1)

# Indices para la partición
nobesidad <- dim(obesidad)[1]
indices <- 1:nobesidad
ntrain <- nobesidad * 0.6
indices.train <- sample(indices, ntrain, replace = FALSE)
indices.test_val <- indices[-indices.train]

# Usamos el 60% para las variables de entrenamiento
train <- obesidad[indices.train, ]
test_val <- obesidad[indices.test_val, ]

# Creamos los indices para test y para val
ntest_val <- dim(test_val)[1]
indices = 1:ntest_val
ntest <-  ntest_val * 0.5
indices.test <- sample(indices, ntest, replace = FALSE)
indices.val <- indices[-indices.test]

# Creamos los datos de test y val
test <- test_val[indices.test, ]
val <- test_val[indices.val, ]

obesidad$Age <- round(obesidad$Age)
obesidad$NCP <- round(obesidad$NCP)
obesidad$FAF <- round(obesidad$FAF)

```


# 1. Planteamiento del Problema

Este conjunto de datos contienen la información para dar una estimación de los niveles de obesidad de personas residentes en Mexico, Perú y Colombia.

En este dataset podemos encontrar distintos tipos de variables:

* Gender: Genero. Variable discreta
* Age: Edad. Variable continua
* Height: Altura (m). Variable continua
* Weight: Peso (kg). Variablel continua
* family_history_with_overweight: Antecedentes familiares. Variable binaria ('yes', 'no')
* FAVC: Consumo frecuente de alimentos de alto valor genético. Variable binaria ('yes', 'no')
* FCVC: Frecuencia de consumo deverduras. Variable continua
* NCP: Número de comidas principales. Variable continua
* CAEC: Consumo de alimentos entre comidas. Variable discreta
* CH2O: Consumo de agua diariamente. Variable continua
* CALC: Consumo de alcohol. Variable discreta  
* SCC: Monitoreo del consumo de calorías. Variable binaria ('yes', 'no')
* FAF: Frecuencias de actividad física. Variable continua
* TUE: Tiempo utilizado dispositivos electronicos. Variable continua
* MTRANS: Transporte utilizado con frecuencia. Variable discreta
* NObeyesdad: Grupos segun el nivel de obesidad, variable discreta se diferencian en:

Dado nuestro problema, que es averiguar el nivel de obesidad de las personas según ciertas variables, buscamos crear un modelo de aprendizaje supervisado para poder averiguar de la forma más precisa el nivel de obesidad que tiene o que puede desarrollar una persona.


# 2. Entrenamiento de modelos y  programación


## 2.1 Modelos


### k-NN

Primero vamos a ver que variable son las necesarias apra poder hacer un buen modelo de knn. Como hemos visto en el EDA, hay ciertas variables que tiene más relación que otras, esas son height, weight, family history with overweight, gender, FAVC (Consumo de alimentos altos en calorias), FAF (Frecuencia de actividad física) y MTRANS (Medio de transporte).

```{r}
# Primero de todo, vamos a usar 10 fold cross validation y lo vamos a repetir 5 veces.
trainControl <- trainControl(method="repeatedcv", number=10, repeats=5)
metric <- "Accuracy"

# Creamos la semilla y buscamos el mejor valor de k para tener un buen modelo.
set.seed(1)

train.df <- train |> select(Gender, Height, Weight, family_history_with_overweight, FAVC, FAF, MTRANS, NObeyesdad)
train.df[,2] <- scale(train.df[,2])
train.df[,3] <- scale(train.df[,3])
train.df[,6] <- scale(train.df[,6])

fit.knn <- train(NObeyesdad ~ ., data=train.df, method="knn", metric=metric ,trControl=trainControl, preProcess = c("center", "scale"))
knn.k1 <- fit.knn$bestTune 
print(fit.knn)
```
Como podemos observar, el mejor valor de k que podemos obtener es de k = 5. Al mirar los resultados podemos ver que el programa ha probado con k = 5 obteniendo una precisión del 80%, aproximadamente, y un indice kappa de 0.76 aproximadamente. Conforma aumentamos el valor de k, en este caso prueba con k = 7 y k = 9, podemos ver como la precisión de nuestro modelo disminuye, al igual que el indice kappa, lo que nos da a entender que cuanto más aumentemos k partiendo de k = 5, pero va a ser nuestro modelo. A continuación vamos a verlo en tabla.

```{r}
plot(fit.knn)
```

Como vemos a partir de k = 5, la precisión de nuestro modelo desciende draticamente. Por lo que viendo el gráfico y las métricas anteriores, podemos observar que k = 5 es el mejor valor que podemos seleccionar. A continuación vamos a obtener la predicción para nuestro conjunto de datos de prueba y vamos a imprimir la matriz de confusión. 

```{r}
set.seed(1)

# Primero calculamos la media de las variables que queremos estandarizar.
# media_height <- mean(train$Height)
# stddev_height <- sqrt(var(train$Height))
# test.df <- test |> mutate(Height=(Height - media_height)/stddev_height)
# 
# media_weight <- mean(train$Weight)
# stddev_weight <- sqrt(var(train$Weight))
# test.df <- test |> mutate(Weight=(Weight - media_weight)/stddev_weight)
# 
# media_FAF <- mean(train$FAF)
# stddev_FAF <- sqrt(var(train$FAF))
# test.df <- test |> mutate(FAF=(FAF - media_FAF)/stddev_FAF)

test.df <- test |> select(Gender, Height, Weight, family_history_with_overweight, FAVC, FAF, MTRANS, NObeyesdad)
test.df[,2] <- scale(test.df[,2])
test.df[,3] <- scale(test.df[,3])
test.df[,6] <- scale(test.df[,6])

prediction <- predict(fit.knn,newdata=test.df)
cf <- confusionMatrix(prediction, as.factor(test.df$NObeyesdad),positive="yes")
print(cf)
```

### Análissi Discriminante Lineal.

Primero de todo, vamos a ver nuestra variable objetivo para ver si es de tipo factor, en caso de no serlo, lo transformamos.

```{r}
str(train$NObeyesdad)
```

Como es de tipo caracter, hacemos el cambio a factor

```{r}
train$NObeyesdad <- as.factor(train$NObeyesdad)
```

Ahora vamos a hacer el análisis discriminante lineal.

```{r}
# Creamos el modelo lda
lda_modelo <- lda(NObeyesdad ~ ., data = train)

# Buscamos las predicciones de lda
lda_predicciones <- predict(lda_modelo)

# Representacion del lda
lda_train <- data.frame(Componente_1 = lda_predicciones$x[, 1], Clase = train$NObeyesdad)

ggplot(lda_train, aes(x = Componente_1, y = 0, color = Clase)) +
  geom_point(size = 3) +
  labs(
    title = "Proyección de LDA",
    x = "Componente discriminante 1",
    y = ""
  ) +
  theme_minimal() +
  scale_color_manual(values = rainbow(length(unique(lda_train$Clase))))
```

Al visualizar la proyección del LDA, podemo ver que en la parte central de las componentes discriminantes hay tipos de obesidad solapados, lo que nos puede indicar que tienen caracteríasticas similares, entre ellos se pueden ver overweight level II y obesity type I, también se puede ver como tenemos valores que están en los extremos, lo que nos puede decir que diferenciarlos de los otros grupos es más senciello. Para estudiar mejor sus diferencias, vamos a hacer un boxplot de las componenetes por clase y un violin plot.

```{r}
# Definir colores
colores <- rainbow(length(unique(lda_train$Clase)))

# Boxplot
boxplot_lda <- ggplot(lda_train, aes(x = Clase, y = Componente_1, fill = Clase)) +
  geom_boxplot(alpha = 0.7) +
  labs(
    title = "Boxplot de la Proyección de LDA",
    x = "Clase",
    y = "Componente Discriminante 1"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 9),
    legend.position = "none" # Ocultar leyenda aquí
  ) +
  scale_fill_manual(values = colores)

# Violin Plot
violinplot_lda <- ggplot(lda_train, aes(x = Clase, y = Componente_1, fill = Clase)) +
  geom_violin(alpha = 0.7) +
  labs(
    title = "Violin Plot de la Proyección de LDA",
    x = "Clase",
    y = "Componente Discriminante 1"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 9),
    legend.position = "none" # Ocultar leyenda aquí también
  ) +
  scale_fill_manual(values = colores)

# Mostrar gráficos
grid.arrange(boxplot_lda, violinplot_lda, ncol = 2)
```

### MÉTODOS DE ENSAMBLADO

Aplicando métodos de ensamblado, podemos mejorar significativamente el rendimiento de predicción, ya que se basa en la unión de múltiples modelos, comenzaremos aplicando el esamblado de bagging.

#### Bagging

```{r}
library(randomForest)
library(caret)

rf <- randomForest(as.factor(NObeyesdad)~., data=train, importance=TRUE,proximity=TRUE) 
print(rf)
```

En cada división interna del árbol, se consideran 4 variables predictoras, lo que contribuye a reducir el sobreajuste. Como podemos observar, se muestra un error OOB de tan solo el 5,45%, esto nos indica una muy buena generalización del modelo.

Además, en la matriz de confusión se muestra como la gran mayoria de las clases de obesidad se clasifican con alta precisión. Todas las clases de obesidad tienen una tasa de error parecida y baja, destacan Obesidad Tipo 1, cuya tasa de error es del 0%, clasificándose correctamente en todos los casos. Por otro lado, Sobrepeso Nivel 1 es la que mayor tipo de error presenta, de un 16,86%, lo que sugiere que es el que mayores disficultades presenta a la hora de clasificar.

Continuamos evaluando visualmente la convergencia del modelo, para anlizar el comportamiento del modelo según se agregan árboles al conjunto.

```{r}
plot(rf)
```

La línea continua muestra el error promedio general, y el resto de líneas discontinuas son los errores según el tipo de obesidad. Algunos errores son muy cercanos a 0, podemos deducir que el rosa (el más bajo) corresponde a Obesidad Tipo 1 ya que su error era de era del 0% y el más elevado a Sobrepeso Nivel 1, ya que su error era el más alto. El error disminuye de manera rápida en las primeras iteraciones y a partir de los 200 árboles se estabiliza, esto demuestra una buena capacidad de generalización del modelo.

```{r}
# sobre la partición de prueba
#df.test <- train %>%
      #dplyr::select(Gender, Age, Height, Weight, family_history_with_overweight, FAVC, FCVC, NCP, CAEC, SMOKE, SCC, FAF, TUE, CH2O, CALC, MTRANS, #NObeyesdad)
#prediction.rf <- predict(rf, df.test,type="prob")[,2]
#clase.pred.rf=ifelse(prediction.rf>0.5,"yes","no")
#cf <- confusionMatrix(as.factor(clase.pred.rf), as.factor(df.test$NObeyesdad),positive="yes")
#print(cf)
```

A continuación, identificamos las variables predictoras que más influyen en las decisiones del modelo:

```{r}
importance(rf)
```

Esta función nos muestra dos medidas clave:

Mean Decrease Accuracy: Muestra cuánto disminuye la precisión del modelo excluimos cada variable.

Mean Decrease Ginni: Mide la pureza de los nodos que aporta cada variable al dividir los datos.

Por lo que según los resultados que hemos obtenido podemos deducir que la variable Weight es la más determinante para predecir el nivel de obesidad, ya que sus valores son los mas altos, su Mean Decrease Accuracy es de 126 y su Mean Decrease Ginni es de 389. Esto tiene total sentido, ya que el nivel de obesidad va ligado al peso y es coherente que sea la variable mas determinante para predecirlo.

Junto al peso, tenemos las variables Altura y Edad, que también son de las más importantes ya que sus valores son los siguientes mas elevados, y por ello también son variables muy relevantes al predecir el nivel de obesidad. También cabe descatar la importancia de ciertas variables como family_history_with_overweight y FCVC, sus valores también son relevantes y esto nos indica que el historial familiar de obesidad y la frecuencia en el consumo de vegetales también tienen una contribución relevante en el modelo.

Por el contrario, variables como SMOKE O SCC, presentan valores muy bajos e incluso negativos, lo que nos sugiere que son poco relevantes a la hora de predecir el nivel de obesidad. Lo cual concuerda con conclusiones anteriores en las que afirmamos que la variable fumar no afecta al nivel de obesidad.

Evaluamos la importancia de las variables:

```{r}
varImpPlot(rf)
```

Al representar graficamente las Mean Decrease Accurancy y Mean Decrease Gini podemos observar de manera más visual como la variables más importante es el peso, lo cual tiene sentido ya que el nivel de obesidad depende del peso. En ambas métricas destacan también de manera muy notable la altura y la edad. Además la frecuencia en el consumo de verduras, el consumo de agua (CH2O) y la frecuencia del consumo de comida calórica (CAEC), también son relevantes, lo que nos puede llevar a concluir la importancia de los hábitos alimenticios en el peso. Por último y coincidencio con lo anterior SCC Y SMOKE vuelven a tener el impacto menos notable en la predicción del modelo.

```{r}
MDSplot(rf,as.factor(train$NObeyesdad),k=3)
```

### NAIVE BAYES

A continuación, vamos a aplicar el método Naive Bayes que estima la clase de obesidad mas probable para cada observación asumiendo independencia entre las variables.

Además, aplicamos Laplace Smoothing (laplace = 1), para evitar que algunas combinaciones de valores tengan probabilidad 0 y así no anulemos la probabilidad total de una clase.

```{r}
library(naivebayes)
library(dplyr)
library(caret)

train$NObeyesdad <- as.factor(train$NObeyesdad)
test$NObeyesdad <- as.factor(test$NObeyesdad)

naive_model <- naive_bayes(NObeyesdad ~ ., data = train, usekernel = TRUE, laplace = 1)
pred_classes <- predict(naive_model, newdata = test)

# Matriz de confusión
confusionMatrix(pred_classes, test$NObeyesdad)

```

Tras aplicarlo, obtenemos una exactitud del 72,5% y un índice Kappa de 0,6775, lo que significa que el modelo tiene una buena capacidad para predecir las clases de obesidad. De hecho, Obesidad de tipo lll, está identificada con una precisión perfecta, sin embargo las clases que peor se ajustan son Sobrepeso Nivel l con sensibilidad del 50% y Sobrepeso Nivel ll con sensibilidad del 54%. Esto tiene sentido si nos fijamos en el análisis anterior usando el método Bagging, en el cual Sobrepeso Nivel l también era la que peor se ajustaba probablemente también por un solapamiento con Sobrepeso Nivel ll.


