---
title: "Obesidad"
author: "Marcos López García"
date: "2025-01-31"
output: html_document
---

```{r echo=FALSE}
library(readr)
library(ggplot2)
library(dplyr)
library(HDclassif)
library(MASS)
library(gt)
library(knitr)
library(cluster)
```

# Introducción

Este conjunto de datos contienen la información para dar una estimación de los niveles de obesidad de personas residentes en Mexico, Perú y Colombia.

Estos datos se han adquirido de [repositorio de datos de kaggle](https://www.kaggle.com/datasets/aravindpcoder/obesity-or-cvd-risk-classifyregressorcluster). Segun la descripción del repositorio, nos basamos en personas con edades entre 14 y 61 años y diversos hábitos alimenticios y condición física. Estos datos se han recolectado mediante una plataforma web con una encuesta donde usuarios anónimos respondieron cada pregunta.

En este dataset podemos encontrar distintos tipos de variables:

* Gender: Genero.
* Age: Edad.
* Height: Altura (m).
* Weight: Peso (kg).
* family_history_with_overweight: Antecedentes familiares.
* FAVC: Consumo frecuente de alimentos de alto valor genético.
* FCVC: Frecuencia de consumo deverduras.
* NCP: Número de comidas principales.
* CAEC: Consumo de alimentos entre comidas.
* CH2O: Consumo de agua diariamente.
* CALC: Consumo de alcohol.
* SCC: Consumo de calorías.
* FAF: Frecuencias de actividad física.
* TUE: Tiempo utilizado dispositivos electronicos.
* MTRANS: Transporte utilizado con frecuencia.
* NObeyesdad: Grupos segun el nivel de obesidad, se diferencian en:

  * Bajo peso: Menos de 18,5.
  * Normal: 18,5 a 24,9.
  * Sobrepeso: 25,0 a 29,9.
  * Obesidad I: 30,0 a 34,9.
  * Obesidad II: 35,0 a 39,9.
  * Obesidad III: Mayor de 40.

# Data understanding

Primero de todo, vamos a cargar los datos y vamos a ver la cantidad de variables y observaciones que encontramos.

```{r}
obesidad <- read.csv("ObesityDataSet.csv")
data <- dim(obesidad)
```
Podemos observar que tenemos una cantiadad de `r data[1]` observaciones y `r data[2]` variables en este dataset

En estos datos, las varibles son de distintos tipos:
```{r}
str(obesidad)
```

Podemos ver como hay distintos tipos de variables en los datos, en el cual solo hay dos tipos, el tipo numérico `num` (`Age`, `Height`, `Weight`, `FCVV`, `NCP`, `CH2O`, `FAF`Y `TUE`) y por otro lado, tenemos vectores de caracteres `char` (`Gender`, `family_history_with_overweight`, `FAVC`, `CAEC`, `SMOKE`, `SSC`, `CALC`, `MTRANS`, `NObeyesdad`)

Antes de hacer la partición de los datos para hacer un mejor análisis, vamos a observar si hay valores faltantes.
```{r}
colSums(is.na(obesidad))
```

Podemos observar que no hay variables de tipo NA, por lo que no es necesario hacer algún tipo de imputación sobre los datos para hacer el análisis de los datos.

Realizamos la partición de nuestros datos.
```{r}
set.seed(1)

# Indices para la partición
nobesidad <- dim(obesidad)[1]
indices <- 1:nobesidad
ntrain <- nobesidad * 0.6
indices.train <- sample(indices, ntrain, replace = FALSE)
indices.test_val <- indices[-indices.train]

# Usamos el 60% para las variables de entrenamiento
train <- obesidad[indices.train, ]
test_val <- obesidad[indices.test_val, ]

# Creamos los indices para test y para val
ntest_val <- dim(test_val)[1]
indices = 1:ntest_val
ntest <-  ntest_val * 0.5
indices.test <- sample(indices, ntest, replace = FALSE)
indices.val <- indices[-indices.test]

# Creamos los datos de test y val
test <- test_val[indices.test, ]
val <- test_val[indices.val, ]
```

Miramos la información de nuestros datos de entrenamiento
```{r}
dim(train)
head(train)
str(train)
```

# EDA

## Variable objetivo

Antes de nada vamos a mirar como se puede ver nuetra variable objetivo, que sería el nivel de obesidad que hay en esta muestra, primero vamos a ver información sobre la variable

```{r}
summary(train$NObeyesdad)
table(train$NObeyesdad)
```

Vamos a visualizar la distribución de las distintas categorías dentro de la variable objetivo NObesity, que se refiere a los distintos niveles de obesidad. Esto lo haremos mediante dos gráficos de barras, en horizontal.

```{r}
train |> 
  ggplot(aes(x = NObeyesdad, fill = NObeyesdad)) +
  geom_bar() +
  theme_bw() + 
  labs(title = "Tipos de obesidad", 
       x = "Tipo de obesidad",
       y = "Frecuencia absoluta") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Tal y como se puede observar en el gráfico, la frecuencia de cada tipo de obesidad es bastante parecida. Podemos ver que la clase que muestra una menor frecuencia es la de peso insuficiente, por otro lado, la clase con una mayor frecuencia es la de Obesidad de tipo I, seguido del peso normal (segunda mayor frecuencia) y de la obesidad de tipo III (tercera mayor frecuencia).Es decir, la categoría que encontramos con mayor frecuencia es obesidad de tipo I.

Comparamos el peso con la altura según el nivel de obesidad
```{r}
train |> ggplot(mapping = aes(x = Height, y = Weight, color = NObeyesdad)) +
  geom_point()
```

**Nivel de obesidad en función de la cantidad de comidas.**

Primero de todo vamos a observar la relación que puede haber entre el tipo de obesidad con el número de comidas que hacen las personas al día.

```{r}
train$FCVC = round(train$FCVC)

ggplot(train, aes(x = FCVC, fill = NObeyesdad , colour = NObeyesdad)) + 
  geom_histogram(position = "dodge", bins = 5)
```

Podemos ver que las personas que hacen una comida son menos propensos de desrrollar obesidad de algún tipo. Por otro lado, hay una cosa que nos parece curiosa y es qe al hacer tres comidas hay bastabtes personas que han desarrollado obesidad de tipo 3 o no tienen el suficiene peso. Viendo esta tabla se puede ver que las personas hacen sobre todo 3 comidas al día.

**Nivel de obesidad según el peso.**

Ahora representaremos los niveles de obesidad distribuidos según el peso mediante un box plot:

```{r}
train |> 
  ggplot(aes(x = NObeyesdad , y = Weight )) +  
  geom_boxplot() +
  theme_bw() +  
  labs(title = "Box-plot de Niveles de Obesidad por peso") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Como podemos observar en el BoxPlot, los niveles de obesidad estan fuertemente relacionados con el peso. Las personas con un mayor peso son las que padecen de Obesidad tipo 3, dentro de esta categoria podemos observar un valor atípico, que se sale por encima del rango, y seria la persona con mas peso entorno a 172,5 kg. La siguiente clase con mas peso son las Obesidad tipo 2, donde también hay ciertos valores atípicos que está vez están por debajo del rango. La tercera categoria con mas peso es la Obesidad tipo 1, donde encontramos al mayor número de personas si recordamos el gráfico anterior. Por último ordenadas de mayor a menor peso encontramos: Sobrepeso nivel 1, Sobrepeso nivel 2, Peso normal y Peso insuficiente.

**Boxplot de los niveles de obesidad distribuidos según la altura.**

```{r}
train |> 
  ggplot(aes(x = NObeyesdad , y = Height )) +  
  geom_boxplot() +
  theme_bw() +  
  labs(title = "Niveles de Obesidad por altura")  +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Aunque algunas categoría presentan distribuciones más amplias no parece haber una diferencia muy grande entre la altura y los niveles de obesidad. Existen valores atípicos en las categorías Obesidad tipo ll (Obesity II ) y Sobrepeso tipo ll (Overweight ll), lo que significa que hay personas con alturas significativamente mas pequeñas a la mayoria de su grupo en el caso de Obesidad tipo ll y también mayores para Sobrepeso tipo ll

**Boxplot de los niveles de obesidad distribuidos según la edad.**

```{r}
train |> 
  ggplot(aes(x = NObeyesdad , y = Age )) +  
  geom_boxplot() +
  theme_bw() +  
  labs(title = "Box-plot de Nieveles de Obesidad por edad")  +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Los niveles de menor peso, Insufficient Weight y Normal Weight, tienen una mediana de edad más baja, entorno a los 20-25 años. Obesity Type l, Obesity Type ll y Obesity Type lll, tienen medianas de edad mas altas, entorno a los 25 años. Podemos observar también que Overweight Level ll tiene una variabilidad mayor en la edad. Encontramos valores atípicos que sobrepasan en la mayoría de categorías. De manera clara podemos concluir que las personas con menor peso tienden a ser más jóvenes, y las personas con un nivel de obesidad mayor tienen una media de edad más alta.

**Nivel de obesidad en función de si fuma o no**

Comparamos la variable objetivo con la variable categórica fumar usando un gráfico de barras:

```{r}
table(train$SMOKE)

```

Como hay una gran diferencia entre el número de personas que fuman y las que no calculamos proporciones dentro de cada grupo para representar un gráfico de barras que muestra la proporción de personas que fuman y las que no dentro de cada tipo de obesidad.

```{r}
# Calcular proporciones dentro de cada grupo de SMOKE
data_prop <- train %>%
  group_by(SMOKE, NObeyesdad) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(SMOKE) %>%
  mutate(prop = count / sum(count) * 100)

ggplot(data_prop, aes(x = NObeyesdad, y = prop, fill = SMOKE)) +
  geom_bar(stat = "identity", position = "dodge") +  # Barras separadas para cada grupo
  labs(x = "Nivel de Obesidad", y = "Proporción (%)", fill = "¿Fuma?",
       title = "Proporción de Niveles de Obesidad según si Fuma o No") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Viendo esta tabla podemos ver que si las personas fuman no tiene una relación con el nivel de obesidad. Debido a que la mayoría de las personas que fuman se encuentran en obisdad de tipo II, sin embargo el siguiente grupo en el que las personas fuman son personas de peso norma. 

Como la dieta está directamente relacionada con el peso, analizaremos como ciertas variables relacionadas con la dieta afectan al peso:

La primera variables que analizaremos es la frecuencia de consumo de comidas con muchas calorias.

```{r}
table(train$FAVC)
```

De nuevo nos encontramos con una diferencia significable entre el número de personas que si consumen comidas con un alto nivel de calorias y las que no, por tanto realizaremos un gráfico de barras que muestra la proporción de personas que consumen este tipo de comidas o no dentro de cada nivel de obesidad.

```{r}
# Calculamos proporciones dentro de cada grupo de FAVC
data_prop <- train %>%
  group_by(FAVC, NObeyesdad) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(FAVC) %>%
  mutate(prop = count / sum(count) * 100)

ggplot(data_prop, aes(x = NObeyesdad, y = prop, fill = FAVC)) +
  geom_bar(stat = "identity", position = "dodge") +  # Barras separadas para cada grupo
  labs(x = "Nivel de Obesidad", y = "Proporción (%)", fill = "¿Consume frecuentemente comidas 
       con un nivel alto de calorias?",
       title = "Proporción de Niveles de Obesidad según si toma comidas con alto nivel de calorias o no") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Tal y como podemos observar, a medida que el nivel de obesidad es mayor la proporción de personas que no comen este tipo de comidas disminuye, recordemos que el orden es:

•Underweight •Normal •Overweight l\
•Overweight ll •Obesity I •Obesity II •Obesity III

Por tanto, podemos sacar como conclusión que el consumo de comidas con alto nivel de calorias efecta directamente al nivel de obesidad de la persona.

Continuaremos analizando otra variable que tiene que ver con la dieta, FCVC que es la frecuencia del consumo de vegetales. Como esta variable es continua, observaremos su distribución por nivel de obesidad de dos maneras mediante un histograma y un boxplot:

Realizaremos un histograma de cada nivel de obesidad y su ditribución del consumo de vegetales para que sea mas claro, ya que al ser varios niveles en un mismo histrograma no se ve con claridad.

```{r}
ggplot(train, aes(x = FCVC, fill = NObeyesdad)) +
  geom_histogram(binwidth = 0.5, alpha = 0.7, position = "identity") +
  facet_wrap(~NObeyesdad) +
  labs(x = "Frecuencia de Consumo de Vegetales", y = "Cantidad de Personas",
       title = "Distribución del Consumo de Vegetales según Nivel de Obesidad") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
train |> 
  ggplot(aes(x = NObeyesdad, y = FCVC)) +  
  geom_boxplot() +  
  theme_bw() +  
  labs(title = "Consumo de vegetales por NIvel de Obesidad") 
```

La siguiente variable será CAEC, que hace referencia a ''comer entre comidas", analizaremos

```{r}
table(train$CAEC)
```

```{r}
train |> 
  ggplot(aes(x = NObeyesdad, fill = CAEC)) +
  geom_bar(position = position_dodge()) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Ahora agrupamos la categoria Mtrans (que asigna el medio de transporte que usan las personas de la muestra) en los que van andando y los que van en transporte, para ver como afecta el movimiento a la obesidad.

```{r}


# Crear la nueva variable de transporte
obesidad_transp <- train %>%
  mutate(MTRANS_grouped = case_when(
    MTRANS %in% c("Automobile", "Motorbike", "Public_Transportation") ~ "No Walking",
    MTRANS %in% c("Walking", "Bike") ~ "Walking",
    TRUE ~ MTRANS # En caso de valores inesperados
  ))
```

Creamos un grafico para las personas que no van andando ni en bici y así poder visualizar su nivel de obesidad.

```{r}
#No Walking

ggplot(filter(obesidad_transp, MTRANS_grouped == "No Walking"), aes(x = NObeyesdad, fill = NObeyesdad)) +
  geom_bar(position = "dodge") +  # Barras separadas
  labs(x = "Nivel de Obesidad", y = "Frecuencia", fill = "NObesity") +
  ggtitle("Frecuencia de NObesity en personas que NO caminan") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Ahora, para las personas que andan, es decir que se mueven creamos otro gráfico para ver su nivel de obesidad.

```{r}
# Walking
ggplot(filter(obesidad_transp, MTRANS_grouped == "Walking"), aes(x = NObeyesdad, fill = NObeyesdad)) +
  geom_bar(position = "dodge") +  # Barras separadas
  labs(x = "Nivel de Obesidad", y = "Frecuencia", fill = "NObesity") +
  ggtitle("Frecuencia de NObesity en personas que caminan") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

El número de personas con obesidad dentro del grupo de las que no caminan es mucho mayor que en el grupo de las que sí caminan, ya que como se puede observar en el segundo gráfico (personas que sí caminan) el número de personas con peso normal (Normal_Weight) es muy elevado. Esto se ajusta y tiene sentido en la realidad, ya que el movimiento que una persona realiza en su día a día está directamente relacionado con tener un peso más o menos elevado.

```{r}

ggplot(filter(obesidad_transp, family_history_with_overweight == "yes"), aes(x = NObeyesdad, fill = NObeyesdad)) +
  geom_bar(position = "dodge") +  # Barras separadas
  labs(x = "Nivel de Obesidad", y = "Frecuencia", fill = "NObesity") +
  ggtitle("Frecuencia de NObesity en personas con Historial familiar de Sobrepeso") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
# Filtrar datos donde la persona NO tiene historial familiar de sobrepeso
ggplot(filter(obesidad_transp, family_history_with_overweight == "no"), aes(x = NObeyesdad, fill = NObeyesdad)) +
  geom_bar(position = "dodge") +  # Barras separadas
  labs(x = "Nivel de Obesidad", y = "Frecuencia", fill = "NObesity") +
  ggtitle("Frecuencia de NObesity en personas sin Historial familiar de Sobrepeso") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

El primer gráfico muestra los niveles de obesidad en personas con un historial familiar de obesidad, tal y como se puede observar, cuanto mayor es el nivel de obesidad, mas personas hay con familiares con obesidad. Ya que, las categorías "peso insuficiente" y "peso normal" son las que menos gente con este historial tienen, en las categorias de sobrepeso (Overweight) el número de personas con familiares con obesidad aumenta y ya por último en las de los tres tipos de obesidad, el número de mucho mayor.

En el segundo gráfico se muestra la otra categoria, pesonas sin historial familiar de sobrepeso. En este caso ocurre lo contrario, cuanto menor es el nivel de obesidad, mayor es la frecuencia con la no existe un historial familiar de sobrepeso. Cabe destacar que en los niveles de Obesidad 1 y 2, la frecuencia es casi nula y en el nivel de Obesidad 3 no hay frecuencia, por lo que no hay nadie con ese nivel de obesidad, que es el más alto, que no tenga un historial familiar de obesidad.

Por tanto, podemos concluir que tener un historial familiar de obesidad afecta directamente al nivel de obesidad de la persona, ya sea por genética o por el estilo de vida.

# PCA

## CON LA FUNCIÓN PRCOMP EN R:

```{r}
library(readr)
 ironman_lake_placid_female_2022 <- read_csv("~/Escritorio/aprendizaje/ironman_lake_placid_female_2022.csv")
```

Ahora trabajaremos con un conjunto de datos sobre participantes femeninas en un triatlon Ironman, las variables que utilizaremos son, Swim.Time, Run.Time y Bike.Time, mediante la función head podemos observar la estructura del conjunto de datos y sus variables:

```{r}
head(ironman_lake_placid_female_2022)
```

Resumen estadístico de cada variable:

```{r}
summary(ironman_lake_placid_female_2022)
```

Observamos la estructura de dataset:

```{r}
str(ironman_lake_placid_female_2022)
```

Como hemos mencionado previamente, las variables que usaremos para PCA son Swim.Time, Run.Time, y Bike.Time (tiempo en cada tipo de carrera), por lo tanto las seleccionamos:

```{r}
#Seleccionamos solo las variables necesarias para hacer el PCA, que son Swim.Time, Bike.Time y Run.Time
ironman_numeric <- ironman_lake_placid_female_2022[, c("Swim.Time", "Bike.Time", "Run.Time")]
```

```{r}
#Eliminamos filas con valores NA
ironman_numeric <- na.omit(ironman_numeric)
# Verificamos si hay valores NA
sum(is.na(ironman_numeric))
#Verificamos que no haya varianza cero en las columnas
ironman_numeric <- ironman_numeric[, sapply(ironman_numeric, function(col) var(col, na.rm = TRUE) > 0)]
```

Realizamos el análisis de componentes principales (PCA) que se basa en simplificar la estructura de datos, preservando al mismo tiempo la mayor cantidad posible de información. Este método convierte un grupo de variables originales en un conjunto nuevo de variables no correlacionadas llamadas componentes principales. Estas nuevas variables capturan la variabilidad presente en los datos de manera más eficiente. Con la función prcomp realizamos el PCA:

```{r}
# Aplicar PCA con escalado
pca_result <- prcomp(ironman_numeric, scale. = TRUE)
```

Visualizamos la importancia relativa de cada componente:

```{r}
plot(prcomp(ironman_numeric,scale=T))
```

```{r}
summary(prcomp(ironman_numeric,scale=T))
```

Como podemos observar, la variabilidad de los datos la explica principalmente la componente principal PC1, ya que en el gráfico de barras es significativamente más alta que las demás. Además en la matriz Rotation PC1 explica el 56,71% de la varianza total. La segunda componente más influyente es PC2, que explica un 33,26%, con las dos primeras variables explicamos el 90% de la variabilidad. A la segunda componente principal la sigue PC3 con un 10%, por lo que esta última es la menos explicativa.

```{r}
prcomp(ironman_numeric,scale=T)
```

PC1 asigna pesos a las variables y al tener todos el mismo signo, significa que hace un promedio ponderado de las variables principales.

```{r}
plot(prcomp(ironman_numeric,scale=T)$x[,1:2])
#No entiendo porque ahora me salen los números así ordenados y abajo al reves
```

Representamos los datos en las dos primeras componentes principales, PC1 Y PC2. La mayoría de los datos están agrupados entorno al valor 0 de la segunda componente principal, por lo que parece que las diferencias entre los datos en la dimensión capturada por PC2 no son muy grandes. Sin embargo, nos encontramos con un valor excepcional el cual se encuentra por debajo del valor -20 de PC2, lo que sugiere que puede tratarse de un atleta con características númericas diferentes en algunas de las variables consideradas. Para analizarlo, vamos a representar los datos con el nombre de cada atleta:

```{r}
rownames(ironman_numeric) <- ironman_lake_placid_female_2022$Name
plot(prcomp(ironman_numeric,scale=T)$x[,1:2], type='n')
text(prcomp(ironman_numeric,scale=T)$x[,1:2],labels=rownames(ironman_numeric))
```

Como podemos leer, la atleta con valores extremos es Dominique Charron:

```{r}
ironman_lake_placid_female_2022[ironman_lake_placid_female_2022$Name == "Dominique Charron", c("Run.Time", "Bike.Time", "Swim.Time")]

```

```{r}
colMeans(ironman_lake_placid_female_2022[, c("Run.Time", "Bike.Time", "Swim.Time")], na.rm = TRUE)

```

Comparándolo con la media de las columnas, la media del valor de Swim.time es 88,1032 y sin embargo, el valor de Swim.Time de Dominique Charron es 3498, por lo que es un valor atípico y su punto en el gráfico se aleja significativamente del resto, vamos a probar a representarlo quitando a esta atleta:

```{r}
# Eliminar la fila 183 
ironman_numeric <- ironman_numeric[-183, ] 
plot(-prcomp(ironman_numeric,scale=T)$x[,1:2])
```

Podemos observar una tendencia a la agrupación en la zona central, por lo que interpretamos que la mayoría de atletas tienen un rendimiento similar entre ellas. Sin embargo, también hay ciertos puntos más alejados de la zona central y por tanto más lejos del resto. Esto nos sugiere que hay atletas con un rendimiento diferenciable, pero gin valores extremadamente alejados como era el caso de Dominique Charron. No podemos observar una separación clara en distintos grupos, pero los valores más cercanos entre ellos tendrán un rendimiento similar.

Además, tal y como hemos visto en la matriz de rotación, como todas las variables originales, (Bike Time, Swim Time y Run Time) tienen pesos negativos en PC1, cuanto mas a la izquierda en el eje x, que es el correspondiente a PC1, mayor es su tiempo en las disciplinas. Por lo tanto, los valores mas a la izquierda corresponden a atletas mas lentos, veamos cuales son los más destacados:

```{r}
ironman_lake_placid_female_2022 <- ironman_lake_placid_female_2022[-183, ] 
rownames(ironman_numeric) <- ironman_lake_placid_female_2022$Bib
plot(-prcomp(ironman_numeric, scale=T)$x[,1:2],type="n")
text(-prcomp(ironman_numeric,scale=T)$x[,1], -prcomp(ironman_numeric, scale=T)$x[,2],rownames(ironman_numeric))
```

Los datos que más a la derecha se encuentran y por tanto deberían ser las atletas más rápidas son los números 3 y 5, vamos a analizar los tiempos de estas atletas en cada una de las disciplinas y ver si efectivamente coincide que sean más rápidas:

```{r}
ironman_lake_placid_female_2022[ironman_lake_placid_female_2022$Bib == "3", c("Name", "Run.Time", "Bike.Time", "Swim.Time") ]
#La mas a la derecha
```

```{r}
ironman_lake_placid_female_2022[ironman_lake_placid_female_2022$Bib == "5", c("Name", "Run.Time", "Bike.Time", "Swim.Time") ]
#La mas a la derecha
```

Media de los tiempos de todas las atletas en cada disciplina:

```         
 Run.Time Bike.Time Swim.Time 
 324.5799  424.7561   88.1032
```

Efectivamente, si lo comparamos con la media de todas las corredoras, Sarah True (3) y Rachel Zilinskas (5) tienen tiempos muy por debajo de la media en las tres disciplinas.

Ahora, realizaremos el mismo análisis para el punto que se encuentra más a la izquierda, que corresponde a la atleta 101.

```{r}
ironman_lake_placid_female_2022[ironman_lake_placid_female_2022$Bib == "101", c("Name", "Run.Time", "Bike.Time", "Swim.Time") ]
#La mas a la izquierda
```

Esta vez, los tiempos de esta atleta están muy por encima de la media, por lo que podemos concluir que efectivamente las atletas mas lentas, y por tanto con tiempos mayores, se encuentran mas a la derecha.

Ahora, lo representamos por colores según si ha superado la media en todas las categorías, si no ha superado la media en ninguna y si lo ha superado en algunas si y en otras no, y como podemos observar en el siguiente gráfico coincide con nuestras conclusiones anteriores:

```{r}
# Calcular el PCA
pca_result <- prcomp(ironman_numeric, scale = TRUE)

# Medias de cada disciplina
media_swim <- 88.1032
media_bike <- 424.7561
media_run  <- 324.5799

swim_times <- ironman_lake_placid_female_2022$Swim.Time
bike_times <- ironman_lake_placid_female_2022$Bike.Time
run_times  <- ironman_lake_placid_female_2022$Run.Time

colores <- ifelse(swim_times < media_swim & bike_times < media_bike & run_times < media_run, "blue", 
           ifelse(swim_times > media_swim & bike_times > media_bike & run_times > media_run, "red",    
                  "green")) 
plot(-pca_result$x[, 1:2], col = colores, pch = 16, 
     xlab = "PC1", ylab = "PC2", main = "PCA según tiempos en Swim, Bike y Run")

# Agregar una leyenda para interpretar los colores
legend("topright", legend = c("Más rápida en todo", "Mixta", "Más lenta en todo"), 
       col = c("blue", "green", "red"), pch = 16)


```
```{r}
biplot(prcomp(ironman_numeric,scale=T)) 
```

La variable PC1 ahora muestra valores negativos a la izquierda y positivos a la derecha, con los tiempos de natación, ciclismo y carrera apuntando hacia valores positivos de PC1. Esto indica que los atletas con tiempos más altos en estas disciplinas se encuentran en la parte derecha del gráfico, mientras que los más rápidos (con tiempos menores) están a la izquierda. Además, el dorsal **3**, que representa a una corredora rápida, ahora aparece correctamente en el lado izquierdo del gráfico, alineándose con la expectativa de que tiempos más cortos correspondan a valores más bajos en PC1.

Los vectores de Swim.Time, Bike.Time y Run.Time muestran cómo se relacionan las variables originales con los componentes principales e indican la dirección en la que crecen los valores de cada variable.

Los vectores apuntan hacia la derecha, lo que sugiere que valores más altos en estas variables están asociados con valores más altos en PC1. Los tres vectores están relativamente alineados, lo que significa que las tres variables están correlacionadas: una atleta con un tiempo alto en natación probablemente también tenga tiempos altos en ciclismo y carrera.

```{r}
#desviaciones típicas de los autovalores
pca_result$sdev
```

```{r}
#Rotation
prcomp(ironman_numeric, scale=T)$rotation
```

```{r}
pca_result$center
```

```{r}
pca_result$scale
```

```{r}
#pca_result$x
```

```{r}
dim(pca_result$x)
```

## Sin usar ninguna función de R específicamente definida para obtener las componentes principales:

**MATRIZ DE COVARIANZA**: El primer paso para realizar un análisis PCA, es calcular la matriz de covarianza.

```{r}
#Seleccionamos solo las variables necesarias para hacer el PCA, que son Swim.Time, Bike.Time y Run.Time
ironman_numeric <- ironman_lake_placid_female_2022[, c("Swim.Time", "Bike.Time", "Run.Time")]
cov_matrix <- cov(ironman_numeric)
cov_matrix
```

**COMPONENTES PRINCIPALES:** El siguiente paso es calcular los autovalores y autovectores usando la matriz de covarianza:

```{r}
#Usamos la función eigen para sacar la descomposición
eigen_decomp <- eigen(cov_matrix)
```

Sacamos autovalores:

```{r}
autovalores <- eigen_decomp$values
autovalores
```

Sacamos autovectores:

```{r}
autovectores <- eigen_decomp$vectors
autovectores
```

Los autovalores y autovectores están ordenados de mayor a menor.

**Selección de componentes principales:**

Anteriormente, habiamos ordenado los autovalores y autovectores de mayor a menor, ya que los primeros componentes principales explican la mayor varianza.

Calcularemos la varianza explicada por cada componente principal diviendo cada autovalor por la suma total de autovalores:

```{r}
varianza_explicada <- autovalores / sum(autovalores)
varianza_explicada
```

```{r}
varianza_acumulada <- cumsum(varianza_explicada)
varianza_acumulada
```

